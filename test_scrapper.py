#!/usr/bin/env python3
"""
Script de diagnostic du scraper TradingEconomics
"""

import sys
sys.path.insert(0, '/mnt/user-data/outputs')

from scraper import TradingEconomicsScraper
import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo

def test_direct_request():
    """Test direct de la requÃªte HTTP"""
    print("=" * 60)
    print("ğŸ§ª TEST 1: RequÃªte HTTP directe")
    print("=" * 60)
    
    url = "https://tradingeconomics.com/calendar"
    today = datetime.now(ZoneInfo("UTC"))
    end_date = today + timedelta(days=7)
    
    params = {
        'd1': today.strftime('%Y-%m-%d'),
        'd2': end_date.strftime('%Y-%m-%d')
    }
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    print(f"ğŸ“ URL: {url}")
    print(f"ğŸ“… PÃ©riode: {params['d1']} â†’ {params['d2']}")
    
    try:
        response = requests.get(url, params=params, headers=headers, timeout=10)
        print(f"âœ… Status Code: {response.status_code}")
        print(f"ğŸ“„ Content Length: {len(response.content):,} bytes")
        print(f"ğŸ“ Content Type: {response.headers.get('content-type', 'N/A')}")
        
        # VÃ©rifier si on a du HTML
        if 'text/html' in response.headers.get('content-type', ''):
            print("âœ… Type de contenu: HTML")
        else:
            print("âš ï¸ Type de contenu inattendu")
        
        return response
        
    except Exception as e:
        print(f"âŒ Erreur requÃªte: {e}")
        return None

def test_html_parsing(response):
    """Test du parsing HTML"""
    print("\n" + "=" * 60)
    print("ğŸ§ª TEST 2: Parsing HTML")
    print("=" * 60)
    
    if not response:
        print("âŒ Pas de rÃ©ponse Ã  parser")
        return
    
    soup = BeautifulSoup(response.content, 'html.parser')
    
    # Chercher la table calendar
    calendar_table = soup.find('table', {'id': 'calendar'})
    print(f"Table 'calendar': {'âœ… TrouvÃ©e' if calendar_table else 'âŒ Introuvable'}")
    
    if calendar_table:
        tbody = calendar_table.find('tbody')
        print(f"Tbody: {'âœ… TrouvÃ©' if tbody else 'âŒ Introuvable'}")
        
        if tbody:
            rows = tbody.find_all('tr')
            print(f"Nombre de lignes: {len(rows)}")
            
            # Afficher les 3 premiÃ¨res lignes pour debug
            print("\nğŸ“‹ PremiÃ¨res lignes:")
            for i, row in enumerate(rows[:3]):
                classes = row.get('class', [])
                print(f"  Ligne {i}: classes={classes}")
                cells = row.find_all('td')
                print(f"    â†’ {len(cells)} cellules")
        else:
            print("\nâš ï¸ Structure de la table:")
            print(f"  Tag de la table: {calendar_table.name}")
            print(f"  Enfants directs: {[child.name for child in calendar_table.children if hasattr(child, 'name')]}")
    else:
        # Chercher d'autres tables possibles
        print("\nğŸ” Recherche d'autres tables:")
        all_tables = soup.find_all('table')
        print(f"  Total de tables trouvÃ©es: {len(all_tables)}")
        
        for i, table in enumerate(all_tables[:3]):
            table_id = table.get('id', 'N/A')
            table_class = table.get('class', [])
            print(f"  Table {i}: id='{table_id}', class={table_class}")

def test_scraper_class():
    """Test de la classe TradingEconomicsScraper"""
    print("\n" + "=" * 60)
    print("ğŸ§ª TEST 3: Classe TradingEconomicsScraper")
    print("=" * 60)
    
    scraper = TradingEconomicsScraper()
    events = scraper.get_calendar_events(days_ahead=7)
    
    print(f"\nğŸ“Š RÃ©sultat:")
    print(f"  Nombre d'Ã©vÃ©nements: {len(events)}")
    
    if events:
        print("\nâœ… Ã‰vÃ©nements trouvÃ©s:")
        for date_key, event in sorted(events.items()):
            print(f"\n  ğŸ“… {date_key}")
            print(f"     {event['country']} {event['name']}")
            print(f"     â° {event['time_paris']} - {event['importance']}")
    else:
        print("\nâŒ Aucun Ã©vÃ©nement trouvÃ©")

def main():
    print("\n" + "ğŸš€" * 30)
    print("DIAGNOSTIC SCRAPER TRADINGECONOMICS")
    print("ğŸš€" * 30 + "\n")
    
    # Test 1: RequÃªte HTTP
    response = test_direct_request()
    
    # Test 2: Parsing HTML
    if response:
        test_html_parsing(response)
    
    # Test 3: Classe scraper
    test_scraper_class()
    
    print("\n" + "=" * 60)
    print("âœ… DIAGNOSTIC TERMINÃ‰")
    print("=" * 60)

if __name__ == "__main__":
    main()
